{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/kushcoshic/anaconda/lib/python2.7/site-packages/matplotlib/font_manager.py:273: UserWarning: Matplotlib is building the font cache using fc-list. This may take a moment.\n",
      "  warnings.warn('Matplotlib is building the font cache using fc-list. This may take a moment.')\n"
     ]
    }
   ],
   "source": [
    "import timeit\n",
    "import scipy as sp\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "plt.ion()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\\begin{equation}\n",
    "f(x) = (2\\pi)^{-\\frac{k}{2}}| \\mathbf{\\Sigma} |^{- \\frac{1}{2}} e^{- \\frac{1}{2}\\ (x-\\mu)\\prime \\ \\mathbf{\\Sigma}^{-1}\\ (x-\\mu )}\\ \\ , \\ \\ \\ k\\equiv dimension\n",
    "\\end{equation}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#start_time = timeit.default_timer()\n",
    "\n",
    "x_start = np.array([[0.,0.],[-0.9,0.9],[-0.9,-0.9],[0.9,-0.9],[0.9,0.9]]) \n",
    "\n",
    "dimension = len(x_start[0])\n",
    "\n",
    "# Multivariate Normal distribution\n",
    "x0=np.matrix([2.5,2.5])\n",
    "x1=np.matrix([-2.5,2.5])\n",
    "cov=np.matrix([[1.,3./5],[3./5,2.]])\n",
    "#cov=np.matrix([[1.,0.],[0.,1.]])\n",
    "det=np.linalg.det(cov)\n",
    "inv=np.linalg.inv(cov)\n",
    "k=2       # dimension\n",
    "def f(x):\n",
    "    x=np.ravel(x)\n",
    "    x=np.matrix(x)\n",
    "    return (((2*np.pi)**(-k/2.))*((det)**(-1/2))*np.exp(-(1./2)*(x-x0)*inv*(x-x0).T)+((2*np.pi)**(-k/2.))*((det)**(-1/2))*np.exp(-(1./2)*(x-x1)*inv*(x-x1).T))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "n_eff_list = []\n",
    "mcmc_step_list = []\n",
    "n_eff_list_y = []\n",
    "\n",
    "#covv=[[1.,0.6],[0.6,2.]]\n",
    "covv=np.matrix([[1.,0.6],[0.6,1.]])\n",
    "mean=[0.,0.]\n",
    "\n",
    "def stepper(x):\n",
    "    x=np.ravel(x)\n",
    "    dx = np.random.multivariate_normal([0.,0.], covv, 1)\n",
    "    return x+dx\n",
    "\n",
    "#global f\n",
    "\n",
    "\n",
    "#ev = np.array([[1.,0.],[0.,1.]])      # Basis vectors chosen for the 2-d space\n",
    "\n",
    "n_eff_min = 500           # effective number of samples\n",
    "mcmc_step = 5000          # MCMC iterations step=size\n",
    "R_max = 1.1               # maximum allowed value for R"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def run_mcmc(f,x_start,stepper,n_eff_min,R_max,mcmc_step):\n",
    "    n_effective = np.zeros(dimension)\n",
    "    n_eff_min_list = np.zeros(dimension)\n",
    "    acceptance_list=[]\n",
    "    for i in range(dimension):\n",
    "        n_eff_min_list[i] = n_eff_min\n",
    "    R_max_list = np.zeros(dimension)\n",
    "    for i in range(dimension):\n",
    "        R_max_list[i] = R_max\n",
    "    \n",
    "    #n_effective_y = 0\n",
    "    z=0\n",
    "    R=0\n",
    "    mcmc_step_remember = mcmc_step\n",
    "    x_recorded = np.zeros((mcmc_step,2,len(x_start)))\n",
    "    while np.any(np.array(n_effective)<n_eff_min_list) or np.any(R>R_max_list):\n",
    "        # MCMC results stored in a 3-d array, 3rd dimension corresponding to every new chain\n",
    "        if z==0:\n",
    "            mcmc_step_0=0\n",
    "            x_recorded = np.zeros((mcmc_step,2,len(x_start)))\n",
    "        else:\n",
    "            x_recorded_template = np.zeros((mcmc_step,2,len(x_start)))         # this if-else is used to store the already computed MCMC samples, before moving to further iterations (if n_eff condition not satisfied). This prevents unecessary wastage of computational power.\n",
    "            x_recorded_template[:mcmc_step_0,:,:]=x_recorded[:,:,:]\n",
    "            x_recorded = x_recorded_template\n",
    "        for i in range(len(x_start)):\n",
    "            x_current = x_start[i]\n",
    "            acceptances = np.zeros(mcmc_step)\n",
    "            for k in range(mcmc_step_0,mcmc_step):\n",
    "                x_new = stepper(x_current)\n",
    "                if np.random.uniform(0,1) < f(x_new)/f(x_current):\n",
    "                    x_current = x_new\n",
    "                    acceptances[k] = 1\n",
    "                x_recorded[k,:,i] = x_current\n",
    "            acceptance_list.append(1.0*acceptances.sum()/len(acceptances))\n",
    "            #print 'For chain %d,'%(i),\n",
    "            #print 'acceptance fraction = %f'%(1.0*acceptances.sum()/len(acceptances))\n",
    "\n",
    "        # Warm up period (extracting only second half of the iterations)\n",
    "        x_warmup = np.zeros((mcmc_step/2,2,len(x_start)))\n",
    "        x_warmup[:,:,:] = x_recorded[mcmc_step/2:,:,:]\n",
    "        #plt.plot(x_warmup[:,0,:],x_warmup[:,1,:],'.',color='b')\n",
    "\n",
    "        # Splitting the chains\n",
    "        x_result = np.zeros((mcmc_step/4,2,2*len(x_start)))\n",
    "        x_result[:,:,0:len(x_start)] = x_warmup[0:mcmc_step/4,:,:]\n",
    "        x_result[:,:,len(x_start):2*len(x_start)] = x_warmup[mcmc_step/4:mcmc_step/2,:,:]\n",
    "        \n",
    "        #global x_result\n",
    "\n",
    "        n=mcmc_step/4.0     # number of iterations in each chain\n",
    "        m=2.0*(len(x_start))    # number of chains\n",
    "\n",
    "        # Assessing mixing using between and within sequence variances\n",
    "\n",
    "        psi = []\n",
    "        for i in range(dimension):\n",
    "            psi.append(x_result[:,i,:])\n",
    "        psi = np.array(psi)\n",
    "        \n",
    "        \n",
    "        psi_dot_j_bar = []\n",
    "        psi_dot_dot_bar = []\n",
    "        B_term = []\n",
    "        B = []\n",
    "        s_j_square_term = []\n",
    "        s_j_square = []\n",
    "        W = []\n",
    "        var_dagger = []\n",
    "        R = []\n",
    "        i_array = []\n",
    "        psi_i_comma_j = []\n",
    "        psi_i_minus_t_comma_j = []\n",
    "        V0 = []\n",
    "        rho0 = []\n",
    "        rho_array_set = []\n",
    "        t_array_set = []\n",
    "        n_effective_list = []\n",
    "        t_array = np.arange(int(n))\n",
    "        sum_rho = 0\n",
    "        sum_rho_list = []\n",
    "        \n",
    "        \n",
    "        for d in range(dimension):\n",
    "            psi_dot_j_bar.append((1/n)*np.sum(psi[d], axis=0))\n",
    "            \n",
    "            psi_dot_dot_bar.append((1/m)*np.sum(psi_dot_j_bar[d]))\n",
    "            \n",
    "            B_term.append(psi_dot_j_bar[d] - psi_dot_dot_bar[d])\n",
    "            \n",
    "            B.append((n/(m-1.0))*np.sum(B_term[d]**2))\n",
    "\n",
    "            s_j_square_term.append(np.zeros((int(n),int(m))))\n",
    "            for j in range(int(m)):\n",
    "                s_j_square_term[d][:,j] = (psi[d][:,j] - psi_dot_j_bar[d][j])**2.0\n",
    "\n",
    "            s_j_square.append((1.0/(n-1))*np.sum(s_j_square_term[d], axis=0))\n",
    "            \n",
    "            W.append((1.0/(m))*np.sum(s_j_square[d]))\n",
    "            \n",
    "\n",
    "            # variance\n",
    "            var_dagger.append(((n-1)/(n))*W[d] + (1/n)*B[d])\n",
    "            \n",
    "            #var_dagger\n",
    "\n",
    "            # potential scale reduction\n",
    "            R.append(np.sqrt(var_dagger[d]/W[d]))\n",
    "            \n",
    "            #R\n",
    "            # Variogram\n",
    "            def V(t):\n",
    "                psi_i_comma_j = psi[d][t+1-1:,:]\n",
    "                \n",
    "                psi_i_minus_t_comma_j = psi[d][0:int(n)-t,:]\n",
    "                \n",
    "                t=float(t)\n",
    "                #V0.append((1/(m*(n-t)))*np.sum(np.sum((psi_i_comma_j[d] - psi_i_minus_t_comma_j[d])**2.0,axis=0)))\n",
    "                return (1.0/(m*(n-t)))*np.sum(np.sum((psi_i_comma_j - psi_i_minus_t_comma_j)**2.0,axis=0))\n",
    "            \n",
    "            # autocorrelation\n",
    "            def rho(t):\n",
    "                #rho0.append(1-(V(t)[d]/(2.0*var_dagger[d])))\n",
    "                return 1.0-(V(t)/(2.0*var_dagger[d]))\n",
    "            \n",
    "\n",
    "            rho_array=np.zeros(int(n))\n",
    "            for t in range(int(n)):\n",
    "                rho_array[t]= rho(int(t))\n",
    "            rho_array_set.append(rho_array)\n",
    "\n",
    "            for i in range(int(n)):\n",
    "                check = rho(i) + rho(i+1)\n",
    "                if check < 0:\n",
    "                    break\n",
    "            i\n",
    "            # effective sample size\n",
    "            n_effective[d]=(m*n)/(1+2.0*np.sum(rho_array[1:i]))\n",
    "            #n_effective_list.append(n_effective)\n",
    "        \n",
    "        mcmc_step_0 = mcmc_step\n",
    "        mcmc_step += mcmc_step_remember\n",
    "        z += 1\n",
    "        #global n_effective_list\n",
    "    \n",
    "    # Finally what we choose as the effective sample size\n",
    "    n_effective_final = np.amin(n_effective)\n",
    "    \n",
    "    # no. of samples to be skipped everytime\n",
    "    samples_skip = 1.0*x_result.shape[2]*x_result.shape[0]/n_effective_final\n",
    "    samples_skip=np.ceil(samples_skip)\n",
    "    \n",
    "    # store the independent samples in samples_final\n",
    "    if int(x_result.shape[0]/samples_skip)==x_result.shape[0]/samples_skip:\n",
    "        samples_final = np.zeros(int((x_result.shape[0])/samples_skip),x_result.shape[1],x_result.shape[2])\n",
    "    else:\n",
    "        samples_final = np.zeros((int(np.ceil((x_result.shape[0])/samples_skip)),x_result.shape[1],x_result.shape[2]))\n",
    "    #samples_final = np.zeros((np.floor(x_result.shape[0]/np.floor(samples_skip))+1,x_result.shape[1],x_result.shape[2]))\n",
    "\n",
    "    samples_final[:,:,:] = x_result[0:x_result.shape[0]:samples_skip,:,:]\n",
    "    \n",
    "    # putting all points of different chains into 1 single array which can be referred to as the final array of samples\n",
    "    samples = np.zeros((samples_final.shape[0]*samples_final.shape[2],2))\n",
    "    for i in range(samples_final.shape[2]):\n",
    "        samples[i*samples_final.shape[0]:(i+1)*samples_final.shape[0],:]=samples_final[:,:,i]\n",
    "    \n",
    "    return n_effective,R,z-1,x_recorded.shape,x_result.shape,x_result,samples_final,samples,acceptance_list,x_recorded\n",
    "\n",
    "\n",
    "run = run_mcmc(f,x_start,stepper,n_eff_min,R_max,mcmc_step)\n",
    "\n",
    "#print (divmod(timeit.default_timer() - start_time, 60))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "samples_final=run[6]\n",
    "\n",
    "samples_final_mean = np.zeros(dimension)\n",
    "samples_final_mean_variance = np.zeros(dimension)\n",
    "for i in range(len(samples_final_mean)):\n",
    "    samples_final_mean[i] = np.mean(samples_final[:,i,:])\n",
    "    samples_final_mean_variance[i] = np.var(samples_final[:,i,:])\n",
    "    \n",
    "print samples_final_mean,samples_final_mean_variance\n",
    "variance = (samples_final_mean_variance[0]**2.0 + samples_final_mean_variance[1]**2.0)**(1/2.0)\n",
    "print variance\n",
    "\n",
    "# Top view plot for effectively independent samples\n",
    "plt.plot(samples_final[:,0,:],samples_final[:,1,:],'.',color='blue') \n",
    "plt.plot(samples_final_mean[0],samples_final_mean[1],'o',color='red')\n",
    "plt.plot(0.,0.,'o',color='g')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "samples_final_1 = np.zeros((samples_final.shape[0],run[5].shape[1],run[5].shape[2]))\n",
    "\n",
    "samples_final_1[:,:,:] = run[5][100:samples_final.shape[0]+100,:,:]\n",
    "\n",
    "samples_final_mean1 = np.zeros(dimension)\n",
    "samples_final_mean1_variance = np.zeros(dimension)\n",
    "for i in range(len(samples_final_mean1)):\n",
    "    samples_final_mean1[i] = np.mean(samples_final_1[:,i,:])\n",
    "    samples_final_mean1_variance[i] = np.var(samples_final_1[:,i,:])\n",
    "    \n",
    "print samples_final_mean1,samples_final_mean1_variance\n",
    "variance1 = (samples_final_mean1_variance[0]**2.0 + samples_final_mean1_variance[1]**2.0)**(1/2.0)\n",
    "print variance\n",
    "\n",
    "# Top view plot for effectively independent samples\n",
    "plt.plot(samples_final_1[:,0,:],samples_final_1[:,1,:],'.',color='blue') \n",
    "plt.plot(samples_final_mean1[0],samples_final_mean1[1],'o',color='red')\n",
    "plt.plot(0.,0.,'o',color='g')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Calculating the autocorrelation in the uncorrelated final sample\n",
    "\n",
    "n = samples_final.shape[0]*1.0\n",
    "m = samples_final.shape[2]*1.0\n",
    "\n",
    "sample_x = samples_final[:,0,:]\n",
    "sample_y = samples_final[:,1,:]\n",
    "\n",
    "def V(t):\n",
    "    sample_x_i_comma_j = sample_x[t+1-1:,:]\n",
    "    sample_x_i_minus_t_comma_j = sample_x[0:int(n)-t,:]\n",
    "    t=float(t)\n",
    "    return (1/(m*(n-t)))*np.sum(np.sum((sample_x_i_comma_j - sample_x_i_minus_t_comma_j)**2.0,axis=0))\n",
    "\n",
    "def rho(t):\n",
    "    return 1-(V(t)/(2.0*samples_final_mean_variance[0]))\n",
    "\n",
    "rho_array = np.zeros(int(n))\n",
    "t_array = np.arange(int(n))\n",
    "\n",
    "for t in range(int(n)):\n",
    "    rho_array[t]= rho(int(t))\n",
    "    \n",
    "plt.plot(t_array,rho_array,'-',color='b')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mu = np.mean(run[7],axis=0)\n",
    "var = np.var(run[7],axis=0)\n",
    "N = run[7].shape[0]\n",
    "z = (mu-0)/np.sqrt(var/N)\n",
    "print z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print samples_final_1.shape\n",
    "samples_1 = np.zeros((samples_final_1.shape[0]*samples_final_1.shape[2],2))\n",
    "for i in range(samples_final_1.shape[2]):\n",
    "    samples_1[i*samples_final_1.shape[0]:(i+1)*samples_final_1.shape[0],:]=samples_final_1[:,:,i]\n",
    "print samples_1.shape\n",
    "\n",
    "mu_1 = np.mean(samples_1,axis=0)\n",
    "var_1 = np.var(samples_1,axis=0)\n",
    "N_1 = samples_1.shape[0]\n",
    "z_1 = (mu-0)/np.sqrt(var_1/N_1)\n",
    "print z_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "plt.figure(1,figsize=(11,5))\n",
    "plt.subplot(1,2,1).set_title('Independent samples')\n",
    "plt.plot(run[5][:,0,:],run[5][:,1,:],'.',color='b')\n",
    "\n",
    "plt.plot(run[7][:,0],run[7][:,1],'.',color='orange')\n",
    "plt.xlabel('x')\n",
    "plt.ylabel('y')\n",
    "\n",
    "plt.subplot(1,2,2).set_title('Correlated samples')\n",
    "plt.plot(run[5][:,0,:],run[5][:,1,:],'.',color='b')\n",
    "\n",
    "plt.plot(samples_1[:,0],samples_1[:,1],'.',color='orange')\n",
    "plt.xlabel('x')\n",
    "plt.ylabel('y')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "run[7].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.cov(run[7].T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "covv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.cov(run[9][:,:,1].T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.cov(run[5][:,:,1].T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.cov(run[9][:,:,0].T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.allclose(np.cov(run[7].T),cov,.06,.06)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.cov(run[7].T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "run[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
